{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32991f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\NT551_11TH\\\\Documents\\\\Streak_Breaking_Solution\\\\data\\\\target\\\\third_more_streak_target.csv\")\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\NT551_11TH\\\\Documents\\\\Streak_Breaking_Solution\\\\data\\\\target\\\\two_streak_target.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c730cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c52005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>TB</th>\n",
       "      <th>...</th>\n",
       "      <th>OPS</th>\n",
       "      <th>target</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>Unnamed: 30</th>\n",
       "      <th>Unnamed: 31</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.271</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.268</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.382</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.306</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AVG  G  PA  AB   R   H  2B  3B  HR  TB  ...    OPS  target  \\\n",
       "0    0.071  1  33  28   1   2   1   0   0   3  ...  0.268       0   \n",
       "1    0.156  1  35  32   1   5   0   0   0   5  ...  0.385       0   \n",
       "2    0.182  1  37  33   4   6   1   0   0   7  ...  0.482       0   \n",
       "3    0.294  1  38  34   2  10   3   0   0  13  ...  0.688       0   \n",
       "4    0.243  1  40  37   2   9   2   0   0  11  ...  0.597       0   \n",
       "..     ... ..  ..  ..  ..  ..  ..  ..  ..  ..  ...    ...     ...   \n",
       "242  0.271  1  56  48   3  13   2   0   0  15  ...  0.677       1   \n",
       "243  0.268  2  83  71  10  19   3   1   2  30  ...  0.784       1   \n",
       "244  0.382  1  39  34   7  13   1   1   2  22  ...  1.094       1   \n",
       "245  0.200  1  38  30   4   6   1   0   1  10  ...  0.657       1   \n",
       "246  0.306  1  38  36   4  11   1   1   0  14  ...  0.731       1   \n",
       "\n",
       "     Unnamed: 27  Unnamed: 28  Unnamed: 29  Unnamed: 30  Unnamed: 31  \\\n",
       "0            NaN          NaN          NaN          NaN          NaN   \n",
       "1            NaN          NaN          NaN          NaN          NaN   \n",
       "2            NaN          NaN          NaN          NaN          NaN   \n",
       "3            NaN          NaN          NaN          NaN          NaN   \n",
       "4            NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "242          NaN          NaN          NaN          NaN          NaN   \n",
       "243          NaN          NaN          NaN          NaN          NaN   \n",
       "244          NaN          NaN          NaN          NaN          NaN   \n",
       "245          NaN          NaN          NaN          NaN          NaN   \n",
       "246          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Unnamed: 32  Unnamed: 33  Unnamed: 34  \n",
       "0            NaN          NaN          NaN  \n",
       "1            NaN          NaN          NaN  \n",
       "2            NaN          NaN          NaN  \n",
       "3            NaN          NaN          NaN  \n",
       "4            NaN          NaN          NaN  \n",
       "..           ...          ...          ...  \n",
       "242          NaN          NaN          NaN  \n",
       "243          NaN          NaN          NaN  \n",
       "244          NaN          NaN          NaN  \n",
       "245          NaN          NaN          NaN  \n",
       "246          NaN          NaN          NaN  \n",
       "\n",
       "[247 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475608bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ca625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>TB</th>\n",
       "      <th>...</th>\n",
       "      <th>IB</th>\n",
       "      <th>SO</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>AVG_</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.271</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.268</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.382</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.200</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.306</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AVG  G  PA  AB   R   H  2B  3B  HR  TB  ...  IB  SO  GDP  SH  SF  \\\n",
       "0    0.071  1  33  28   1   2   1   0   0   3  ...   0   9    0   2   0   \n",
       "1    0.156  1  35  32   1   5   0   0   0   5  ...   0   8    0   0   0   \n",
       "2    0.182  1  37  33   4   6   1   0   0   7  ...   0   5    0   0   0   \n",
       "3    0.294  1  38  34   2  10   3   0   0  13  ...   0   7    0   2   1   \n",
       "4    0.243  1  40  37   2   9   2   0   0  11  ...   0   6    0   0   0   \n",
       "..     ... ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ...  ..  ..   \n",
       "242  0.271  1  56  48   3  13   2   0   0  15  ...   2  14    0   1   0   \n",
       "243  0.268  2  83  71  10  19   3   1   2  30  ...   0  11    1   0   1   \n",
       "244  0.382  1  39  34   7  13   1   1   2  22  ...   0   4    2   1   0   \n",
       "245  0.200  1  38  30   4   6   1   0   1  10  ...   0   9    0   1   1   \n",
       "246  0.306  1  38  36   4  11   1   1   0  14  ...   0   4    2   0   0   \n",
       "\n",
       "      AVG_    OBP    SLG    OPS  target  \n",
       "0    0.071  0.161  0.107  0.268       0  \n",
       "1    0.156  0.229  0.156  0.385       0  \n",
       "2    0.182  0.270  0.212  0.482       0  \n",
       "3    0.294  0.306  0.382  0.688       0  \n",
       "4    0.243  0.300  0.297  0.597       0  \n",
       "..     ...    ...    ...    ...     ...  \n",
       "242  0.271  0.364  0.313  0.677       1  \n",
       "243  0.268  0.361  0.423  0.784       1  \n",
       "244  0.382  0.447  0.647  1.094       1  \n",
       "245  0.200  0.324  0.333  0.657       1  \n",
       "246  0.306  0.342  0.389  0.731       1  \n",
       "\n",
       "[247 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0b63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0f867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017fb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGB\": XGBClassifier(eval_metric=\"logloss\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a8d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg Training ===\n",
      "==================================================\n",
      " Model: LogisticRegression\n",
      "Accuracy : 0.7800\n",
      "F1-score : 0.7660\n",
      "ROC-AUC  : 0.8958\n",
      "PR-AUC   : 0.9069\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7778    0.8077    0.7925        26\n",
      "           1     0.7826    0.7500    0.7660        24\n",
      "\n",
      "    accuracy                         0.7800        50\n",
      "   macro avg     0.7802    0.7788    0.7792        50\n",
      "weighted avg     0.7801    0.7800    0.7797        50\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[21  5]\n",
      " [ 6 18]]\n",
      "\n",
      "=== RF Training ===\n",
      "==================================================\n",
      " Model: RandomForestClassifier\n",
      "Accuracy : 0.7600\n",
      "F1-score : 0.7391\n",
      "ROC-AUC  : 0.9038\n",
      "PR-AUC   : 0.8950\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.8077    0.7778        26\n",
      "           1     0.7727    0.7083    0.7391        24\n",
      "\n",
      "    accuracy                         0.7600        50\n",
      "   macro avg     0.7614    0.7580    0.7585        50\n",
      "weighted avg     0.7609    0.7600    0.7592        50\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[21  5]\n",
      " [ 7 17]]\n",
      "\n",
      "=== XGB Training ===\n",
      "==================================================\n",
      " Model: XGBClassifier\n",
      "Accuracy : 0.7800\n",
      "F1-score : 0.7660\n",
      "ROC-AUC  : 0.8734\n",
      "PR-AUC   : 0.8657\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7778    0.8077    0.7925        26\n",
      "           1     0.7826    0.7500    0.7660        24\n",
      "\n",
      "    accuracy                         0.7800        50\n",
      "   macro avg     0.7802    0.7788    0.7792        50\n",
      "weighted avg     0.7801    0.7800    0.7797        50\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[21  5]\n",
      " [ 6 18]]\n",
      "\n",
      " 모델별 성능 비교\n",
      "        accuracy        f1   roc_auc    pr_auc\n",
      "LogReg      0.78  0.765957  0.895833  0.906852\n",
      "RF          0.76  0.739130  0.903846  0.895024\n",
      "XGB         0.78  0.765957  0.873397  0.865709\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# === 1) 데이터 준비 ===\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Train / Test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 스케일링 \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# === 2) 모델 정의 ===\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGB\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# === 3) 평가 함수 정의 ===\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = None\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:,1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_proba = model.decision_function(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    pr  = average_precision_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(f\" Model: {type(model).__name__}\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "    if roc is not None:\n",
    "        print(f\"ROC-AUC  : {roc:.4f}\")\n",
    "    if pr is not None:\n",
    "        print(f\"PR-AUC   : {pr:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"--- Confusion Matrix ---\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return {\"accuracy\":acc, \"f1\":f1, \"roc_auc\":roc, \"pr_auc\":pr}\n",
    "\n",
    "# === 4) 모델 학습 & 평가 ===\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} Training ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    results[name] = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# === 5) 결과 비교 ===\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n 모델별 성능 비교\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1c8635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Logistic] Best params: {'clf__C': 1, 'clf__penalty': 'l1'} | Best CV ROC-AUC: 0.8537\n",
      "\n",
      "=== Logistic ===\n",
      "ROC-AUC: 0.8942 | PR-AUC: 0.9033 | F1@0.5: 0.7600 | F1@J(0.660): 0.7805\n",
      "\n",
      "-- Classification Report (thr=0.5) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7917    0.7308    0.7600        26\n",
      "           1     0.7308    0.7917    0.7600        24\n",
      "\n",
      "    accuracy                         0.7600        50\n",
      "   macro avg     0.7612    0.7612    0.7600        50\n",
      "weighted avg     0.7624    0.7600    0.7600        50\n",
      "\n",
      "-- Confusion Matrix (thr=0.5) --\n",
      "[[19  7]\n",
      " [ 5 19]]\n",
      "\n",
      "-- Classification Report (thr=J) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7576    0.9615    0.8475        26\n",
      "           1     0.9412    0.6667    0.7805        24\n",
      "\n",
      "    accuracy                         0.8200        50\n",
      "   macro avg     0.8494    0.8141    0.8140        50\n",
      "weighted avg     0.8457    0.8200    0.8153        50\n",
      "\n",
      "-- Confusion Matrix (thr=J) --\n",
      "[[25  1]\n",
      " [ 8 16]]\n",
      "\n",
      "[RandomForest] Best params: {'clf__max_depth': 6, 'clf__min_samples_split': 2, 'clf__n_estimators': 400} | Best CV ROC-AUC: 0.8358\n",
      "\n",
      "=== RandomForest ===\n",
      "ROC-AUC: 0.9071 | PR-AUC: 0.8994 | F1@0.5: 0.7391 | F1@J(0.360): 0.8627\n",
      "\n",
      "-- Classification Report (thr=0.5) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.8077    0.7778        26\n",
      "           1     0.7727    0.7083    0.7391        24\n",
      "\n",
      "    accuracy                         0.7600        50\n",
      "   macro avg     0.7614    0.7580    0.7585        50\n",
      "weighted avg     0.7609    0.7600    0.7592        50\n",
      "\n",
      "-- Confusion Matrix (thr=0.5) --\n",
      "[[21  5]\n",
      " [ 7 17]]\n",
      "\n",
      "-- Classification Report (thr=J) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9130    0.8077    0.8571        26\n",
      "           1     0.8148    0.9167    0.8627        24\n",
      "\n",
      "    accuracy                         0.8600        50\n",
      "   macro avg     0.8639    0.8622    0.8599        50\n",
      "weighted avg     0.8659    0.8600    0.8598        50\n",
      "\n",
      "-- Confusion Matrix (thr=J) --\n",
      "[[21  5]\n",
      " [ 2 22]]\n",
      "\n",
      "[GBDT] Best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 150} | Best CV ROC-AUC: 0.8461\n",
      "\n",
      "=== GBDT ===\n",
      "ROC-AUC: 0.8862 | PR-AUC: 0.8682 | F1@0.5: 0.7727 | F1@J(0.300): 0.8400\n",
      "\n",
      "-- Classification Report (thr=0.5) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7667    0.8846    0.8214        26\n",
      "           1     0.8500    0.7083    0.7727        24\n",
      "\n",
      "    accuracy                         0.8000        50\n",
      "   macro avg     0.8083    0.7965    0.7971        50\n",
      "weighted avg     0.8067    0.8000    0.7981        50\n",
      "\n",
      "-- Confusion Matrix (thr=0.5) --\n",
      "[[23  3]\n",
      " [ 7 17]]\n",
      "\n",
      "-- Classification Report (thr=J) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.8077    0.8400        26\n",
      "           1     0.8077    0.8750    0.8400        24\n",
      "\n",
      "    accuracy                         0.8400        50\n",
      "   macro avg     0.8413    0.8413    0.8400        50\n",
      "weighted avg     0.8427    0.8400    0.8400        50\n",
      "\n",
      "-- Confusion Matrix (thr=J) --\n",
      "[[21  5]\n",
      " [ 3 21]]\n",
      "\n",
      "[XGBoost] Best params: {'clf__gamma': 0, 'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__min_child_weight': 1} | Best CV ROC-AUC: 0.8442\n",
      "\n",
      "=== XGBoost ===\n",
      "ROC-AUC: 0.8718 | PR-AUC: 0.8533 | F1@0.5: 0.7391 | F1@J(0.270): 0.8163\n",
      "\n",
      "-- Classification Report (thr=0.5) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.8077    0.7778        26\n",
      "           1     0.7727    0.7083    0.7391        24\n",
      "\n",
      "    accuracy                         0.7600        50\n",
      "   macro avg     0.7614    0.7580    0.7585        50\n",
      "weighted avg     0.7609    0.7600    0.7592        50\n",
      "\n",
      "-- Confusion Matrix (thr=0.5) --\n",
      "[[21  5]\n",
      " [ 7 17]]\n",
      "\n",
      "-- Classification Report (thr=J) --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8400    0.8077    0.8235        26\n",
      "           1     0.8000    0.8333    0.8163        24\n",
      "\n",
      "    accuracy                         0.8200        50\n",
      "   macro avg     0.8200    0.8205    0.8199        50\n",
      "weighted avg     0.8208    0.8200    0.8201        50\n",
      "\n",
      "-- Confusion Matrix (thr=J) --\n",
      "[[21  5]\n",
      " [ 4 20]]\n",
      "\n",
      "=== Summary (sorted by ROC_AUC) ===\n",
      "          model   ROC_AUC    PR_AUC    F1@0.5  BestThreshold(J)      F1@J\n",
      "1  RandomForest  0.907051  0.899359  0.739130              0.36  0.862745\n",
      "0      Logistic  0.894231  0.903285  0.760000              0.66  0.780488\n",
      "2          GBDT  0.886218  0.868221  0.772727              0.30  0.840000\n",
      "3       XGBoost  0.871795  0.853270  0.739130              0.27  0.816327\n",
      "\n",
      "Saved: model_outputs\\model_metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Streak 프로젝트: 통합 모델링 스크립트\n",
    "# ======================\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score,\n",
    "    precision_recall_fscore_support, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 선택형: 설치되어 있으면 사용\n",
    "has_xgb = True\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    has_xgb = False\n",
    "\n",
    "# ----------------------\n",
    "# 0) 파일 경로 & 로드\n",
    "# ----------------------\n",
    "# 필요에 따라 경로 수정 가능\n",
    "CANDIDATE_PATHS = [\n",
    "    \"dataset_with_features_target_last.csv\",                  # 현재 작업 디렉토리\n",
    "    r\"C:\\\\Users\\\\NT551_11TH\\\\Documents\\\\Streak_Breaking_Solution\\\\data\\\\dataset_with_features_target_last.csv\",\n",
    "    \"/mnt/data/dataset_with_features_target_last.csv\",\n",
    "]\n",
    "\n",
    "def read_csv_fallback(paths):\n",
    "    last_err = None\n",
    "    for p in paths:\n",
    "        if not Path(p).exists():\n",
    "            continue\n",
    "        try:\n",
    "            try:\n",
    "                return pd.read_csv(p)\n",
    "            except UnicodeDecodeError:\n",
    "                return pd.read_csv(p, encoding=\"cp949\")\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise FileNotFoundError(f\"CSV를 찾거나 읽지 못했습니다. 시도한 경로: {paths}\\n마지막 오류: {last_err}\")\n",
    "\n",
    "df = read_csv_fallback(CANDIDATE_PATHS).copy()\n",
    "\n",
    "# ----------------------\n",
    "# 1) 타겟 분리 (마지막 컬럼이 타겟)\n",
    "# ----------------------\n",
    "target_col = df.columns[-1]\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# y가 범주형/문자형이면 0/1로 변환 시도\n",
    "if not np.issubdtype(y.dtype, np.number):\n",
    "    y = y.astype(str).str.strip().str.lower()\n",
    "    # 흔한 표기 매핑\n",
    "    mapping = {\"win\":1, \"loss\":0, \"true\":1, \"false\":0, \"yes\":1, \"no\":0, \"1\":1, \"0\":0}\n",
    "    y = y.map(lambda v: mapping.get(v, v))\n",
    "    # 여전히 숫자가 아니면 이진 레이블 인코딩\n",
    "    if not pd.api.types.is_numeric_dtype(y):\n",
    "        classes = sorted(y.dropna().unique())\n",
    "        if len(classes) != 2:\n",
    "            raise ValueError(f\"타겟이 이진이 아닙니다. 고유값: {classes}\")\n",
    "        y = y.map({classes[0]:0, classes[1]:1}).astype(int)\n",
    "    else:\n",
    "        y = y.astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 2) 컬럼 타입 감지\n",
    "# ----------------------\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "# 파이프라인용 변환기\n",
    "num_tf = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_tf = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_tf, num_cols),\n",
    "        (\"cat\", cat_tf, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 3) 데이터 분할\n",
    "# ----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 4) 모델 & 그리드\n",
    "# ----------------------\n",
    "models = {\n",
    "    \"Logistic\": Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"saga\"))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        # 트리에 스케일 불필요하지만 결측 대체는 필요 → 수치/범주형 둘 다 단순 대체만 적용\n",
    "        (\"prep\", ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "                (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                                  (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]),\n",
    "                 cat_cols),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "    \"GBDT\": Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "param_grids = {\n",
    "    \"Logistic\": {\n",
    "        \"clf__C\": [0.1, 1, 2, 5],\n",
    "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"clf__n_estimators\": [200, 400],\n",
    "        \"clf__max_depth\": [None, 6, 10],\n",
    "        \"clf__min_samples_split\": [2, 5]\n",
    "    },\n",
    "    \"GBDT\": {\n",
    "        \"clf__n_estimators\": [150, 300],\n",
    "        \"clf__learning_rate\": [0.05, 0.1],\n",
    "        \"clf__max_depth\": [2, 3]\n",
    "    }\n",
    "}\n",
    "if has_xgb:\n",
    "    models[\"XGBoost\"] = Pipeline([\n",
    "        (\"prep\", ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "                (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                                  (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]),\n",
    "                 cat_cols),\n",
    "            ],\n",
    "            remainder=\"drop\"\n",
    "        )),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            random_state=42, n_estimators=500, subsample=0.9, colsample_bytree=0.9,\n",
    "            eval_metric=\"logloss\", tree_method=\"hist\", n_jobs=0\n",
    "        ))\n",
    "    ])\n",
    "    param_grids[\"XGBoost\"] = {\n",
    "        \"clf__max_depth\": [3, 5, 7],\n",
    "        \"clf__learning_rate\": [0.05, 0.1],\n",
    "        \"clf__min_child_weight\": [1, 3],\n",
    "        \"clf__gamma\": [0, 1]\n",
    "    }\n",
    "\n",
    "# ----------------------\n",
    "# 5) 학습 & 평가 함수\n",
    "# ----------------------\n",
    "def evaluate_model(name, estimator, X_tr, y_tr, X_te, y_te):\n",
    "    # 확률 예측\n",
    "    proba = estimator.predict_proba(X_te)[:, 1]\n",
    "    # 기본 임계값 0.5\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    # 지표\n",
    "    roc = roc_auc_score(y_te, proba)\n",
    "    pr  = average_precision_score(y_te, proba)\n",
    "    f1  = f1_score(y_te, pred)\n",
    "\n",
    "    # Youden's J로 최적 임계값 탐색(간단 스캔)\n",
    "    thresholds = np.linspace(0.1, 0.9, 81)\n",
    "    best_j, best_t = -1, 0.5\n",
    "    for t in thresholds:\n",
    "        p = (proba >= t).astype(int)\n",
    "        # TPR, FPR\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, p).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp+fn) else 0\n",
    "        fpr = fp / (fp + tn) if (fp+tn) else 0\n",
    "        j = tpr - fpr\n",
    "        if j > best_j:\n",
    "            best_j, best_t = j, t\n",
    "    pred_j = (proba >= best_t).astype(int)\n",
    "\n",
    "    out = {\n",
    "        \"model\": name,\n",
    "        \"ROC_AUC\": roc,\n",
    "        \"PR_AUC\": pr,\n",
    "        \"F1@0.5\": f1,\n",
    "        \"BestThreshold(J)\": round(best_t, 4),\n",
    "        \"F1@J\": f1_score(y_te, pred_j),\n",
    "    }\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {pr:.4f} | F1@0.5: {f1:.4f} | F1@J({best_t:.3f}): {out['F1@J']:.4f}\")\n",
    "    print(\"\\n-- Classification Report (thr=0.5) --\")\n",
    "    print(classification_report(y_te, pred, digits=4))\n",
    "    print(\"-- Confusion Matrix (thr=0.5) --\")\n",
    "    print(confusion_matrix(y_te, pred))\n",
    "    print(\"\\n-- Classification Report (thr=J) --\")\n",
    "    print(classification_report(y_te, pred_j, digits=4))\n",
    "    print(\"-- Confusion Matrix (thr=J) --\")\n",
    "    print(confusion_matrix(y_te, pred_j))\n",
    "    return out\n",
    "\n",
    "# ----------------------\n",
    "# 6) GridSearchCV로 모델 비교\n",
    "# ----------------------\n",
    "results = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    grid = param_grids.get(name, {})\n",
    "    if grid:\n",
    "        gs = GridSearchCV(\n",
    "            pipe,\n",
    "            grid,\n",
    "            scoring=\"roc_auc\",\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            refit=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        gs.fit(X_train, y_train)\n",
    "        best_est = gs.best_estimator_\n",
    "        print(f\"\\n[{name}] Best params: {gs.best_params_} | Best CV ROC-AUC: {gs.best_score_:.4f}\")\n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        best_est = pipe\n",
    "        print(f\"\\n[{name}] (no grid) trained.\")\n",
    "\n",
    "    res = evaluate_model(name, best_est, X_train, y_train, X_test, y_test)\n",
    "    results.append(res)\n",
    "\n",
    "# ----------------------\n",
    "# 7) 결과 요약 테이블\n",
    "# ----------------------\n",
    "summary = pd.DataFrame(results).sort_values(\"ROC_AUC\", ascending=False)\n",
    "print(\"\\n=== Summary (sorted by ROC_AUC) ===\")\n",
    "print(summary)\n",
    "\n",
    "# (선택) CSV로 저장\n",
    "out_dir = Path(\"./model_outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "summary.to_csv(out_dir / \"model_metrics_summary.csv\", index=False)\n",
    "print(f\"\\nSaved: {out_dir / 'model_metrics_summary.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa46914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== logreg_l1 (GridSearchCV) ===\n",
      "Best params: {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__max_iter': 500, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best CV ROC-AUC: 0.7934\n",
      "Accuracy: 0.8077 | F1: 0.8148 | Precision: 0.8462 | Recall: 0.7857\n",
      "ROC-AUC: 0.8810 | PR-AUC: 0.9291\n",
      "\n",
      "Confusion Matrix:\n",
      " [[10  2]\n",
      " [ 3 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        12\n",
      "           1       0.85      0.79      0.81        14\n",
      "\n",
      "    accuracy                           0.81        26\n",
      "   macro avg       0.81      0.81      0.81        26\n",
      "weighted avg       0.81      0.81      0.81        26\n",
      "\n",
      "\n",
      "=== random_forest (GridSearchCV) ===\n",
      "Best params: {'clf__class_weight': 'balanced_subsample', 'clf__max_depth': None, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__random_state': 42}\n",
      "Best CV ROC-AUC: 0.8190\n",
      "Accuracy: 0.7308 | F1: 0.7407 | Precision: 0.7692 | Recall: 0.7143\n",
      "ROC-AUC: 0.9226 | PR-AUC: 0.9411\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 9  3]\n",
      " [ 4 10]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72        12\n",
      "           1       0.77      0.71      0.74        14\n",
      "\n",
      "    accuracy                           0.73        26\n",
      "   macro avg       0.73      0.73      0.73        26\n",
      "weighted avg       0.73      0.73      0.73        26\n",
      "\n",
      "\n",
      "=== gradient_boosting (GridSearchCV) ===\n",
      "Best params: {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 200, 'clf__random_state': 42, 'clf__subsample': 0.8}\n",
      "Best CV ROC-AUC: 0.7612\n",
      "Accuracy: 0.7692 | F1: 0.7857 | Precision: 0.7857 | Recall: 0.7857\n",
      "ROC-AUC: 0.8869 | PR-AUC: 0.9244\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 9  3]\n",
      " [ 3 11]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.79      0.79      0.79        14\n",
      "\n",
      "    accuracy                           0.77        26\n",
      "   macro avg       0.77      0.77      0.77        26\n",
      "weighted avg       0.77      0.77      0.77        26\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SUMMARY (sorted by ROC_AUC)\n",
      "================================================================================\n",
      " rank_by_roc_auc             model  cv_roc_auc  roc_auc  pr_auc  accuracy     f1  precision  recall                                                                                                                                                                     best_params\n",
      "               1     random_forest      0.8190   0.9226  0.9411    0.7308 0.7407     0.7692  0.7143 {'clf__class_weight': 'balanced_subsample', 'clf__max_depth': None, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__random_state': 42}\n",
      "               2 gradient_boosting      0.7612   0.8869  0.9244    0.7692 0.7857     0.7857  0.7857                                                     {'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 200, 'clf__random_state': 42, 'clf__subsample': 0.8}\n",
      "               3         logreg_l1      0.7934   0.8810  0.9291    0.8077 0.8148     0.8462  0.7857                                                          {'clf__C': 1, 'clf__class_weight': 'balanced', 'clf__max_iter': 500, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "\n",
      "Best model by ROC_AUC: random_forest\n",
      "Best params: {'clf__class_weight': 'balanced_subsample', 'clf__max_depth': None, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 2, 'clf__n_estimators': 300, 'clf__random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grids = {\n",
    "    \"logreg_l1\": {\n",
    "        \"clf__C\": [0.1, 0.5, 1, 2, 5],\n",
    "        \"clf__penalty\": [\"l1\"],  # liblinear\n",
    "        \"clf__solver\": [\"liblinear\"],\n",
    "        \"clf__max_iter\": [500],\n",
    "        \"clf__class_weight\": [\"balanced\"]\n",
    "    },\n",
    "    \"random_forest\": {\n",
    "        \"clf__n_estimators\": [300, 500, 800],\n",
    "        \"clf__max_depth\": [None, 5, 10, 20],\n",
    "        \"clf__min_samples_split\": [2, 5, 10],\n",
    "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "        \"clf__class_weight\": [\"balanced_subsample\"],\n",
    "        \"clf__random_state\": [42]\n",
    "    },\n",
    "    \"gradient_boosting\": {\n",
    "        \"clf__n_estimators\": [100, 200, 400],\n",
    "        \"clf__learning_rate\": [0.03, 0.05, 0.1],\n",
    "        \"clf__max_depth\": [2, 3, 4],\n",
    "        \"clf__subsample\": [0.8, 1.0],\n",
    "        \"clf__random_state\": [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "trained = {}\n",
    "metrics_rows = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "    grid = GridSearchCV(\n",
    "        pipe, param_grid=grids[name],\n",
    "        scoring=\"roc_auc\", cv=cv, n_jobs=-1, refit=True, verbose=0\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_pipe = grid.best_estimator_\n",
    "    trained[name] = best_pipe\n",
    "\n",
    "    print(f\"\\n=== {name} (GridSearchCV) ===\")\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    print(f\"Best CV ROC-AUC: {grid.best_score_:.4f}\")\n",
    "\n",
    "    # 평가\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    # 확률(또는 점수) 확보\n",
    "    if hasattr(best_pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        y_prob = best_pipe.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(best_pipe.named_steps[\"clf\"], \"decision_function\"):\n",
    "        s = best_pipe.decision_function(X_test)\n",
    "        y_prob = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1  = f1_score(y_test, y_pred, zero_division=0)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "    roc = roc_auc_score(y_test, y_prob) if y_prob is not None else np.nan\n",
    "    prauc = average_precision_score(y_test, y_prob) if y_prob is not None else np.nan\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f} | F1: {f1:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n",
    "    if y_prob is not None:\n",
    "        print(f\"ROC-AUC: {roc:.4f} | PR-AUC: {prauc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # === summary용 행 추가 ===\n",
    "    metrics_rows.append({\n",
    "        \"model\": name,\n",
    "        \"cv_roc_auc\": grid.best_score_,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"roc_auc\": roc,\n",
    "        \"pr_auc\": prauc,\n",
    "        \"best_params\": grid.best_params_\n",
    "    })\n",
    "\n",
    "# ======================================\n",
    "#            SUMMARY SECTION\n",
    "# ======================================\n",
    "summary_df = pd.DataFrame(metrics_rows)\n",
    "\n",
    "display_cols = [\"model\", \"cv_roc_auc\", \"roc_auc\", \"pr_auc\", \"accuracy\", \"f1\", \"precision\", \"recall\", \"best_params\"]\n",
    "summary_df_formatted = summary_df[display_cols].copy()\n",
    "for c in [\"cv_roc_auc\", \"roc_auc\", \"pr_auc\", \"accuracy\", \"f1\", \"precision\", \"recall\"]:\n",
    "    summary_df_formatted[c] = summary_df_formatted[c].astype(float).round(4)\n",
    "\n",
    "# 랭킹 기준 선택\n",
    "\n",
    "ranking_metric = \"roc_auc\"\n",
    "summary_df_formatted = summary_df_formatted.sort_values(by=ranking_metric, ascending=False).reset_index(drop=True)\n",
    "summary_df_formatted.insert(0, \"rank_by_\"+ranking_metric, range(1, len(summary_df_formatted)+1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SUMMARY (sorted by {ranking_metric.upper()})\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df_formatted.to_string(index=False))\n",
    "\n",
    "best_row = summary_df_formatted.iloc[0]\n",
    "best_model_name = best_row[\"model\"]\n",
    "print(\"\\nBest model by {0}: {1}\".format(ranking_metric.upper(), best_model_name))\n",
    "print(\"Best params:\", summary_df.loc[summary_df[\"model\"]==best_model_name, \"best_params\"].item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095326d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
